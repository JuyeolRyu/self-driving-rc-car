cap = cv2.VideoCapture(0)

while(cap.isOpened()):
    ret,image = cap.read()
    image = cv2.resize(image, (224, 224)) # window 사이즈 조정
    height, width = image.shape[:2] # 이미지 높이, 너비
    cv2.imshow('result',image) # 결과 이미지 출력
mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
    #turn the image into a numpy array
    image_array = np.asarray(frame)
    
    # Normalize the image
    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1

    # Load the image into the array
    data[0] = normalized_image_array

    # run the inference
    prediction = model.predict(data)
    direction = ''
    
    if prediction[0][0] >= 0.9: # STOP
        direction = 'background'
        print('background')

    elif prediction[0][1] >= 0.9: # SLOW
        direction = 'box'
        print('box')
        setdrive(F, 0.1)

    elif prediction[0][2] >= 0.9: # LEFT
        direction = 'phone'
        print('phone')
        setdrive(B, 0.1)

    elif prediction[0][3] >= 0.9: # HUMAN
        direction = 'cup'
        print('cup')
        setdrive(S, 0.1)

    elif prediction[0][4] >= 0.9: # NONE

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

GPIO.cleanup()
cap.release()
cv2.destroyAllWindows()