{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n",
      "\n",
      "48.36646066342981\n"
     ]
    }
   ],
   "source": [
    "import cv2 # opencv 사용\n",
    "\n",
    "import numpy as np\n",
    "from math import *\n",
    "from time import sleep\n",
    "\n",
    "# =========================== \n",
    "\n",
    "def grayscale(img): # 흑백이미지로 변환\n",
    "\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    " \n",
    "\n",
    "def canny(img, low_threshold, high_threshold): # Canny 알고리즘\n",
    "\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    " \n",
    "\n",
    "def gaussian_blur(img, kernel_size): # 가우시안 필터\n",
    "\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    " \n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "\n",
    " \n",
    "\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "\n",
    "    \n",
    "\n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "\n",
    "        color = color3\n",
    "\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "\n",
    "        color = color1\n",
    "\n",
    "        \n",
    "\n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "\n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "\n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return ROI_image\n",
    "\n",
    " \n",
    "\n",
    "# 허프변환 라인 그리기 (확인용)\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 255, 0], thickness=2):\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        for x1,y1,x2,y2 in line:\n",
    "\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "            #cv2.imshow('result2', img)\n",
    "\n",
    " \n",
    "\n",
    "# 허프 변환\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): \n",
    "    print()\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    draw_lines(line_img, lines)\n",
    "\n",
    " \n",
    "\n",
    "    return lines\n",
    "\n",
    "    #return line_img\n",
    "\n",
    " \n",
    "\n",
    "# 두 이미지 operlap 하기\n",
    "\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): \n",
    "\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    " \n",
    "\n",
    "# '대표선' 구하기 (62, 63줄 코드 이해 X )\n",
    "\n",
    "def get_fitline(img, f_lines): \n",
    "\n",
    "    lines = np.squeeze(f_lines)\n",
    "\n",
    "    if(len(lines.shape) == 1): #선이 하나밖에 없는 경우 배열의 모양 따로 조정\n",
    "\n",
    "        lines = lines.reshape(2,2)\n",
    "\n",
    "    else:\n",
    "\n",
    "        lines = lines.reshape(lines.shape[0]*2,2)\n",
    "\n",
    "    rows,cols = img.shape[:2]\n",
    "\n",
    "    output = cv2.fitLine(lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "\n",
    "    x1, y1 = int(((img.shape[0]/2+70)-y)/vy*vx + x) , int(img.shape[0]/2+70)\n",
    "\n",
    "    x2, y2 = int(((img.shape[0]/2-25)-y)/vy*vx + x) , int(img.shape[0]/2-25)\n",
    "\n",
    "    \n",
    "\n",
    "    result = [x1,y1,x2,y2]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# '대표선' 그리기\n",
    "\n",
    "def draw_fit_line(img, lines, color=[255, 0, 0], thickness=10):\n",
    "\n",
    "        # cv2.line(이미지, 시작좌표(0, 0), 끝좌표(500, 500), 색깔, 두께)\n",
    "\n",
    "        cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness) \n",
    "\n",
    " \n",
    "\n",
    "# '대표선' 이용해서 -> 소실점 구하기 (공식)\n",
    "\n",
    "def expression(x1,y1,x2,y2,x3,y3,x4,y4):\n",
    "\n",
    "    m_a = (y2 - y1) / (x2 -x1)\n",
    "\n",
    "    m_b = (y4 - y3) / (x4 - x3)\n",
    "\n",
    "    n_a = -((y2 - y1) / (x2 - x1) * x1 ) + y1\n",
    "\n",
    "    n_b = -((y4 - y3) / (x4 -x3) * x3 ) + y3\n",
    "\n",
    "    x = (n_b - n_a) / (m_a - m_b) \n",
    "\n",
    "    y = m_a * ((n_b - n_a) / (m_a - m_b)) + n_a \n",
    "\n",
    "    return x,y\n",
    "\n",
    " \n",
    "\n",
    "cap = cv2.VideoCapture('테스트영상4.MP4') # 960x540\n",
    "\n",
    "#cap = cv2.VideoCapture('testvideo.mp4') # 1920x1080 -> 에러\n",
    "\n",
    " \n",
    "PERMIT_DIST = 10 #forward 판단 범위(거리 + -)\n",
    "while(cap.isOpened()):\n",
    "\n",
    " \n",
    "\n",
    "    ret,image = cap.read()\n",
    "\n",
    "    #image = cv2.resize(image, (640, 360)) # window 사이즈 조정\n",
    "\n",
    " \n",
    "\n",
    "    height, width = image.shape[:2] # 이미지 높이, 너비\n",
    " \n",
    "\n",
    "    m_width = int(width/2)\n",
    "\n",
    " \n",
    "\n",
    "    gray_img = grayscale(image) # 흑백이미지로 변환\n",
    "\n",
    "    \n",
    "\n",
    "    blur_img = gaussian_blur(gray_img, 3) # Blur 효과\n",
    "\n",
    "    \n",
    "\n",
    "    min_threshold = 70\n",
    "\n",
    "    max_trheshold = 210\n",
    "\n",
    "    canny_img = canny(blur_img, min_threshold, max_trheshold) # Canny edge 알고리즘\n",
    "\n",
    "\n",
    "    #vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "\n",
    "    #vertices = np.array([[(0,height/2+30),(width/2-140, height/2-60), (width/2+140, height/2-60), (width,height/2+30)]], dtype=np.int32)\n",
    "    vertices = np.array([[(0,height),\n",
    "                      (0,height/2-25),\n",
    "                      (width/2-70, height/2-60),\n",
    "                      (width/2+70, height/2-60),\n",
    "                      (width,height/2-25),\n",
    "                      (width,height)]], dtype=np.int32)\n",
    "    \n",
    "    ROI_img = region_of_interest(canny_img, vertices) # ROI 설정\n",
    "\n",
    "    \n",
    "\n",
    " \n",
    "    rho = 1\n",
    "\n",
    "    theta = 1 * np.pi/180\n",
    "\n",
    "    threshold = 30    # threshold 값이  작으면 그만큼 기준이 낮아져 많은 직선이 검출될 것이고, 값을 높게 정하면 그만큼 적지만 확실한 직선들만 검출이 될 것이다\n",
    "    \n",
    "    \n",
    "    line_arr = hough_lines(ROI_img, rho, theta, threshold, 10, 20) # 허프 변환\n",
    "\n",
    "    #print(line_arr.shape) # (8,1,4), (7,1,4) ...(3,1,4) ...\n",
    "\n",
    "    #print(line_arr[:]) # [ [[523 330 870 538]], [[707 450 848 538]], ...]\n",
    "\n",
    "    \n",
    "\n",
    "    line_arr = np.squeeze(line_arr) # remove single dimension (차원을 하나 줄임)\n",
    "\n",
    "    #print(line_arr.shape) # (8, 4), (7, 4), ...(3, 4) ...\n",
    "\n",
    "    #print(line_arr[:]) # [[523 330 870 538], [707 450 848 538] ...]\n",
    "\n",
    "    \n",
    "\n",
    "# 기울기 구하기 (arctan(y,x)이용)\n",
    "\n",
    "    # arr[: , 3]  => 모든행에서, 열의 인덱스가 3인값(=4열)을 추출 \n",
    "\n",
    "    slope_degree = np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180 / np.pi\n",
    "\n",
    "    #print('slope_degree = ', slope_degree)  # [-149.06053163 -148.03115746 -147.99461679  144.0329697   142.96378706\n",
    "\n",
    "                                             #-147.77873319 -147.89374404  144.12500865 -148.44861505  142.94347181\n",
    "\n",
    "                                             #-148.98611594  144.3601908  -148.94323092 -147.60015983  140.9374161 ]\n",
    "\n",
    "    \n",
    "\n",
    "# 수평 기울기 제한\n",
    "\n",
    "    line_arr = line_arr[np.abs(slope_degree)<175]\n",
    "\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)<175]\n",
    "\n",
    "# 수직 기울기 제한\n",
    "\n",
    "    line_arr = line_arr[np.abs(slope_degree)>95]\n",
    "\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "\n",
    "# 필터링된 직선 버리기\n",
    "\n",
    "    L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]\n",
    "\n",
    "    #print('L_lines = ', L_lines)\n",
    "\n",
    "\n",
    "    L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "\n",
    "    \n",
    "\n",
    "    if(len(L_lines) == 0 and len(R_lines) == 0): #L_lines, R_lines 모두 없는 경우\n",
    "\n",
    "        L_lines = pre_left_line\n",
    "\n",
    "        R_lines = pre_right_line\n",
    "\n",
    "    elif(len(L_lines) == 0):#L_lines만 없는 경우\n",
    "\n",
    "        L_lines = pre_left_line\n",
    "\n",
    "        pre_right_line = R_lines\n",
    "\n",
    "    elif(len(R_lines) == 0):#R_lines만 없는 경우\n",
    "\n",
    "        R_lines = pre_right_line\n",
    "\n",
    "        pre_left_line = L_lines\n",
    "\n",
    "    else:#라인 모두 검출한 경우\n",
    "\n",
    "        pre_right_line = R_lines\n",
    "\n",
    "        pre_left_line = L_lines\n",
    "\n",
    "    #print('L_lines = ', L_lines)\n",
    "\n",
    "\n",
    "\n",
    "    temp = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    #print(temp[:])\n",
    "\n",
    "\n",
    "\n",
    "# 왼쪽, 오른쪽 각각 대표선 구하기\n",
    "\n",
    "    left_fit_line = get_fitline(image,L_lines)\n",
    "\n",
    "    right_fit_line = get_fitline(image,R_lines)\n",
    "\n",
    "    #print(left_fit_line) # [158, 539, 388, 370] -> 단 1개 검출 \n",
    "\n",
    "    \n",
    "\n",
    "# 대표선 '그리기'\n",
    "\n",
    "    draw_fit_line(temp, left_fit_line)\n",
    "\n",
    "    draw_fit_line(temp, right_fit_line)\n",
    "\n",
    "    #print('left_fit_line = ', left_fit_line) # [158, 539, 388, 370]\n",
    "\n",
    " \n",
    "\n",
    "    vanishing_point = expression(left_fit_line[0],left_fit_line[1],left_fit_line[2],left_fit_line[3],right_fit_line[0],right_fit_line[1],right_fit_line[2],right_fit_line[3])\n",
    "\n",
    "    #print(vanishing_point) # (476.9880952380953, 304.61309523809524)...\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    v_x = int(vanishing_point[0])\n",
    "\n",
    "    v_y = int(vanishing_point[1])\n",
    "\n",
    "    #print(v_x, v_y) # 476 304 ...\n",
    "\n",
    "    \n",
    "\n",
    "    result = weighted_img(temp, image) # 원본 이미지(=image)에 검출된 선(=temp) overlap\n",
    "\n",
    "    cv2.circle(result, (v_x,v_y), 6, (0,0,255), -1) # cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "\n",
    "    \n",
    "\n",
    "    #circle 기준선(보조선)\n",
    "\n",
    "    cv2.line(result,(m_width,0),(m_width,300),(255,255,0),5) # cv2.line(image, start_point, end_point, color, thickness)\n",
    "\n",
    " \n",
    "    cv2.imshow('result',result)\n",
    "    \n",
    "    \n",
    "    temp_x, temp_y = m_width/2 , height/2\n",
    "    #소실점 v_x,v_y 기준점 : m_width,height\n",
    "    angle = int(atan2(height - temp_y,m_width - temp_x)*180/pi)\n",
    "    \n",
    "    print(angle)\n",
    "    \n",
    "    if(v_x > m_witdh + PERMIT_DIST):#오른쪽\n",
    "        angle = angle - 90\n",
    "    elif(v_x < m_witdh - PERMIT_DIST): #왼쪽\n",
    "        angle = 90 - angle\n",
    "    else: #foward\n",
    "    \n",
    "    cv2.imshow('result',result) # 결과 이미지 출력\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
