{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#from motor import *\n",
    "def mark_img(img, blue_threshold=200, green_threshold=200, red_threshold=200): # 1. 흰색 차선 찾기\n",
    "    mark = img\n",
    "    #  BGR 제한 값 (기준)\n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "    # BGR 제한 값(기준)보다 작으면 검은색으로\n",
    "    thresholds = (img[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (img[:,:,1] < bgr_threshold[1]) \\\n",
    "                | (img[:,:,2] < bgr_threshold[2])\n",
    "    mark[thresholds] = [0,0,0] # 검정색으로 \n",
    "    return mark\n",
    " \n",
    "def grayscale(img): # 흑백이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "        color = color3\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "        color = color1\n",
    "        \n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return ROI_image\n",
    "\n",
    "# 허프변환 라인 그리기 (확인용)\n",
    "def draw_lines(img, lines, color=[255, 255, 0], thickness=2):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\\\n",
    "            \n",
    "# 허프 변환\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "\n",
    "    return lines\n",
    "\n",
    "# 두 이미지 operlap 하기\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): \n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "# '대표선' 구하기 (62, 63줄 코드 이해 X )\n",
    "def get_fitline(img, f_lines): \n",
    "    lines = np.squeeze(f_lines)\n",
    "    if(len(lines.shape) == 1): #선이 하나밖에 없는 경우 배열의 모양 따로 조정\n",
    "        lines = lines.reshape(2,2)\n",
    "    else:\n",
    "        lines = lines.reshape(lines.shape[0]*2,2)\n",
    "\n",
    "    rows,cols = img.shape[:2]\n",
    "    output = cv2.fitLine(lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0]/2+70)-y)/vy*vx + x) , int(img.shape[0]/2+70)\n",
    "    x2, y2 = int(((img.shape[0]/2-25)-y)/vy*vx + x) , int(img.shape[0]/2-25)\n",
    "    result = [x1,y1,x2,y2]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# '대표선' 그리기\n",
    "def draw_fit_line(img, lines, color=[255, 0, 0], thickness=10):\n",
    "        # cv2.line(이미지, 시작좌표(0, 0), 끝좌표(500, 500), 색깔, 두께)\n",
    "        cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness) \n",
    "\n",
    "# '대표선' 이용해서 -> 소실점 구하기 (공식)\n",
    "def expression(x1,y1,x2,y2,x3,y3,x4,y4):\n",
    "    m_a = (y2 - y1) / (x2 -x1)\n",
    "    m_b = (y4 - y3) / (x4 - x3)\n",
    "    n_a = -((y2 - y1) / (x2 - x1) * x1 ) + y1\n",
    "    n_b = -((y4 - y3) / (x4 -x3) * x3 ) + y3\n",
    "    x = (n_b - n_a) / (m_a - m_b) \n",
    "    y = m_a * ((n_b - n_a) / (m_a - m_b)) + n_a \n",
    "\n",
    "    return x,y\n",
    " \n",
    "\n",
    "#=======================================\n",
    "\n",
    " \n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = tensorflow.keras.models.load_model('keras_model.h5',compile = False)\n",
    "\n",
    " \n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    ret,image = cap.read()\n",
    "\n",
    "    image2 = cv2.resize(image, (224, 224)) # window 사이즈 조정\n",
    "    \n",
    "\n",
    "    height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "    \n",
    "    #cv2.imshow('result2',image2)\n",
    "    cv2.imshow('result2',image2) # 결과 이미지 출력\n",
    "    cv2.imshow('result',image) # 결과 이미지 출력\n",
    " \n",
    "\n",
    "    #turn the image into a numpy array\n",
    "\n",
    "    image_array = np.asarray(image2)\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize the image\n",
    "\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    \n",
    " \n",
    "\n",
    "    # Load the image into the array\n",
    "\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    # run the inference\n",
    "\n",
    "    prediction = model.predict(data)\n",
    "\n",
    " \n",
    "\n",
    "    direction = ''\n",
    "\n",
    "    if prediction[0][0] >= 0.8:\n",
    "        #direction = F\n",
    "        print('forward!!')\n",
    "\n",
    " \n",
    "\n",
    "    elif prediction[0][1] >= 0.8:\n",
    "        #direction = FR\n",
    "        print('right!!')\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
