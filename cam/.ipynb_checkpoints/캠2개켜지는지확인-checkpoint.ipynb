{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n",
      "forward!!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#from motor import *\n",
    "def mark_img(img, blue_threshold=200, green_threshold=200, red_threshold=200): # 1. 흰색 차선 찾기\n",
    "    mark = img\n",
    "    #  BGR 제한 값 (기준)\n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "    # BGR 제한 값(기준)보다 작으면 검은색으로\n",
    "    thresholds = (img[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (img[:,:,1] < bgr_threshold[1]) \\\n",
    "                | (img[:,:,2] < bgr_threshold[2])\n",
    "    mark[thresholds] = [0,0,0] # 검정색으로 \n",
    "    return mark\n",
    " \n",
    "def grayscale(img): # 흑백이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "        color = color3\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "        color = color1\n",
    "        \n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return ROI_image\n",
    "\n",
    "# 허프변환 라인 그리기 (확인용)\n",
    "def draw_lines(img, lines, color=[255, 255, 0], thickness=2):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\\\n",
    "            \n",
    "# 허프 변환\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "\n",
    "    return lines\n",
    "\n",
    "# 두 이미지 operlap 하기\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): \n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "# '대표선' 구하기 (62, 63줄 코드 이해 X )\n",
    "def get_fitline(img, f_lines): \n",
    "    lines = np.squeeze(f_lines)\n",
    "    if(len(lines.shape) == 1): #선이 하나밖에 없는 경우 배열의 모양 따로 조정\n",
    "        lines = lines.reshape(2,2)\n",
    "    else:\n",
    "        lines = lines.reshape(lines.shape[0]*2,2)\n",
    "\n",
    "    rows,cols = img.shape[:2]\n",
    "    output = cv2.fitLine(lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0]/2+70)-y)/vy*vx + x) , int(img.shape[0]/2+70)\n",
    "    x2, y2 = int(((img.shape[0]/2-25)-y)/vy*vx + x) , int(img.shape[0]/2-25)\n",
    "    result = [x1,y1,x2,y2]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# '대표선' 그리기\n",
    "def draw_fit_line(img, lines, color=[255, 0, 0], thickness=10):\n",
    "        # cv2.line(이미지, 시작좌표(0, 0), 끝좌표(500, 500), 색깔, 두께)\n",
    "        cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness) \n",
    "\n",
    "# '대표선' 이용해서 -> 소실점 구하기 (공식)\n",
    "def expression(x1,y1,x2,y2,x3,y3,x4,y4):\n",
    "    m_a = (y2 - y1) / (x2 -x1)\n",
    "    m_b = (y4 - y3) / (x4 - x3)\n",
    "    n_a = -((y2 - y1) / (x2 - x1) * x1 ) + y1\n",
    "    n_b = -((y4 - y3) / (x4 -x3) * x3 ) + y3\n",
    "    x = (n_b - n_a) / (m_a - m_b) \n",
    "    y = m_a * ((n_b - n_a) / (m_a - m_b)) + n_a \n",
    "\n",
    "    return x,y\n",
    " \n",
    "\n",
    "#=======================================\n",
    "\n",
    " \n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = tensorflow.keras.models.load_model('keras_model.h5',compile = False)\n",
    "\n",
    " \n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    ret,image = cap.read()\n",
    "\n",
    "    image2 = cv2.resize(image, (224, 224)) # window 사이즈 조정\n",
    "    \n",
    "\n",
    "    height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "    \n",
    "    #cv2.imshow('result2',image2)\n",
    "    \n",
    "    cv2.imshow('result',image) # 결과 이미지 출력\n",
    " \n",
    "\n",
    "    #turn the image into a numpy array\n",
    "\n",
    "    image_array = np.asarray(image2)\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize the image\n",
    "\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    \n",
    " \n",
    "\n",
    "    # Load the image into the array\n",
    "\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    # run the inference\n",
    "\n",
    "    prediction = model.predict(data)\n",
    "\n",
    " \n",
    "    m_width = int(width/2)\n",
    "\n",
    "    mrk_img = mark_img(image)\n",
    "    gray_img = grayscale(mrk_img)\n",
    "    ####################################################################\n",
    "    vertices = np.array([[(350,height-150),\n",
    "                          (600,360),\n",
    "                          (800,360),\n",
    "                          (width-100,height-150)]], dtype=np.int32)\n",
    "    ####################################################################\n",
    "    ROI_img = region_of_interest(gray_img, vertices) # ROI 설정\n",
    "    ####################################################################\n",
    "    rho = 1\n",
    "    theta = 1 * np.pi/180\n",
    "    threshold = 30    # threshold 값이  작으면 그만큼 기준이 낮아져 많은 직선이 검출될 것이고, 값을 높게 정하면 그만큼 적지만 확실한 직선들만 검출이 될 것이다\n",
    "    ####################################################################\n",
    "    \n",
    "    line_arr = hough_lines(ROI_img, rho, theta, threshold, 10, 20) # 허프 변환\n",
    "    line_arr = np.squeeze(line_arr) # remove single dimension (차원을 하나 줄임)\n",
    "\n",
    "    # 기울기 구하기 (arctan(y,x)이용)\n",
    "    slope_degree = np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180 / np.pi\n",
    "\n",
    "# 수평 기울기 제한\n",
    "    line_arr = line_arr[np.abs(slope_degree)<175]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)<175]\n",
    "# 수직 기울기 제한\n",
    "    line_arr = line_arr[np.abs(slope_degree)>95]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "# 필터링된 직선 버리기\n",
    "    L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]\n",
    "    L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "\n",
    "    if(len(L_lines) == 0 and len(R_lines) == 0): #L_lines, R_lines 모두 없는 경우\n",
    "        L_lines = pre_left_line\n",
    "        R_lines = pre_right_line\n",
    "    elif(len(L_lines) == 0):#L_lines만 없는 경우\n",
    "        L_lines = pre_left_line\n",
    "        pre_right_line = R_lines\n",
    "    elif(len(R_lines) == 0):#R_lines만 없는 경우\n",
    "        R_lines = pre_right_line\n",
    "        pre_left_line = L_lines\n",
    "    else:#라인 모두 검출한 경우\n",
    "        pre_right_line = R_lines\n",
    "        pre_left_line = L_lines\n",
    "\n",
    "    temp = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "# 왼쪽, 오른쪽 각각 대표선 구하기\n",
    "    left_fit_line = get_fitline(image,L_lines)\n",
    "    right_fit_line = get_fitline(image,R_lines)\n",
    "    #print(left_fit_line) # [158, 539, 388, 370] -> 단 1개 검출 \n",
    "\n",
    "# 대표선 '그리기'\n",
    "    draw_fit_line(temp, left_fit_line)\n",
    "    draw_fit_line(temp, right_fit_line)\n",
    "    #print('left_fit_line = ', left_fit_line) # [158, 539, 388, 370]\n",
    "\n",
    "    vanishing_point = expression(left_fit_line[0],left_fit_line[1],left_fit_line[2],left_fit_line[3],right_fit_line[0],right_fit_line[1],right_fit_line[2],right_fit_line[3])\n",
    "    #print(vanishing_point) # (476.9880952380953, 304.61309523809524)...\n",
    "\n",
    "    v_x = int(vanishing_point[0])\n",
    "    v_y = int(vanishing_point[1])\n",
    "\n",
    "    result = weighted_img(temp, image) # 원본 이미지(=image)에 검출된 선(=temp) overlap\n",
    "    cv2.circle(result, (v_x,v_y), 6, (0,0,255), -1) # cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "\n",
    "    #circle 기준선(보조선)\n",
    "    cv2.line(result,(m_width,0),(m_width,300),(255,255,0),5) # cv2.line(image, start_point, end_point, color, thickness)\n",
    "    \n",
    "    if(m_width != v_x):\n",
    "        slope_degree = float(v_y) / (m_width - v_x)\n",
    "    else:\n",
    "        slope_degree = 0\n",
    "    print(slope_degree)\n",
    "    if(slope_degree > 2.475): # degree 22\n",
    "        print(\"Right!!!\")\n",
    "        #cv2.circle(result,(1000,50), 6,(0,0,255),-1) # (1000,50)에 circle 찍어라 \n",
    "    elif(slope_degree < -2.475): # 소실점의 x좌표가 중앙선보다 왼쪽에 있을때\n",
    "        print(\"Left!!!\")\n",
    "        #cv2.circle(result,(100,50), 6,(0,0,255),-1) # (100,50)에 circle 찍어라\n",
    "    else:\n",
    "        print(\"foward!!!\")\n",
    "    \n",
    "    cv2.imshow('CV',result) # 결과 이미지 출력\n",
    "    cv2.imshow('TM',image2) # 결과 이미지 출력\n",
    "    \n",
    "    if prediction[0][0] >= 0.8:\n",
    "        #direction = F\n",
    "        print('forward!!')\n",
    "\n",
    " \n",
    "\n",
    "    elif prediction[0][1] >= 0.8:\n",
    "        #direction = FR\n",
    "        print('right!!')\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
